{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Importing libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "# references: \n",
    "# 1) https://www.codementor.io/bruce3557/beautiful-machine-learning-pipeline-with-scikit-learn-uiqapbxuj\n",
    "# 2) https://medium.com/vickdata/a-simple-guide-to-scikit-learn-pipelines-4ac0d974bdcf#targetText=Scikit%2Dlearn%20pipelines%20are%20a,of%20steps%20in%20your%20project.\n",
    "# 3) https://michelleful.github.io/code-blog/2015/06/20/pipelines/\n",
    "# 4) http://zacstewart.com/2014/08/05/pipelines-of-featureunions-of-pipelines.html\n",
    "# 5) https://www.dataquest.io/blog/introduction-to-ensembles/\n",
    "# 6) https://www.pluralsight.com/guides/ensemble-modeling-scikit-learn\n",
    "\n",
    "# dataset: https://www.kaggle.com/ronitf/heart-disease-uci/download\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.model_selection import train_test_split, RepeatedStratifiedKFold, GridSearchCV, cross_val_score\n",
    "from sklearn.pipeline import Pipeline, FeatureUnion\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, KBinsDiscretizer\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.linear_model import Lasso, LogisticRegression\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, VotingClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "warnings.filterwarnings('ignore') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Basic setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('heart.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(303, 14)"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Only needed when combining df's of separate 'data' and 'target objects'\n",
    "# train_df = pd.DataFrame(\n",
    "#     data = np.append(data.target[:, None], data.data, axis=1), \n",
    "#     columns = ['target'] + data.feature_names\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>63</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>145</td>\n",
       "      <td>233</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>150</td>\n",
       "      <td>0</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>37</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>250</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>3.5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>41</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>204</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>1.4</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>56</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>120</td>\n",
       "      <td>236</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>178</td>\n",
       "      <td>0</td>\n",
       "      <td>0.8</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>354</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>163</td>\n",
       "      <td>1</td>\n",
       "      <td>0.6</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age  sex  cp  trestbps  chol  fbs  restecg  thalach  exang  oldpeak  slope  \\\n",
       "0   63    1   3       145   233    1        0      150      0      2.3      0   \n",
       "1   37    1   2       130   250    0        1      187      0      3.5      0   \n",
       "2   41    0   1       130   204    0        0      172      0      1.4      2   \n",
       "3   56    1   1       120   236    0        1      178      0      0.8      2   \n",
       "4   57    0   0       120   354    0        1      163      1      0.6      2   \n",
       "\n",
       "   ca  thal  target  \n",
       "0   0     1       1  \n",
       "1   0     2       1  \n",
       "2   0     2       1  \n",
       "3   0     2       1  \n",
       "4   0     2       1  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>cp</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>restecg</th>\n",
       "      <th>thalach</th>\n",
       "      <th>exang</th>\n",
       "      <th>oldpeak</th>\n",
       "      <th>slope</th>\n",
       "      <th>ca</th>\n",
       "      <th>thal</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "      <td>303.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>54.366337</td>\n",
       "      <td>0.683168</td>\n",
       "      <td>0.966997</td>\n",
       "      <td>131.623762</td>\n",
       "      <td>246.264026</td>\n",
       "      <td>0.148515</td>\n",
       "      <td>0.528053</td>\n",
       "      <td>149.646865</td>\n",
       "      <td>0.326733</td>\n",
       "      <td>1.039604</td>\n",
       "      <td>1.399340</td>\n",
       "      <td>0.729373</td>\n",
       "      <td>2.313531</td>\n",
       "      <td>0.544554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>9.082101</td>\n",
       "      <td>0.466011</td>\n",
       "      <td>1.032052</td>\n",
       "      <td>17.538143</td>\n",
       "      <td>51.830751</td>\n",
       "      <td>0.356198</td>\n",
       "      <td>0.525860</td>\n",
       "      <td>22.905161</td>\n",
       "      <td>0.469794</td>\n",
       "      <td>1.161075</td>\n",
       "      <td>0.616226</td>\n",
       "      <td>1.022606</td>\n",
       "      <td>0.612277</td>\n",
       "      <td>0.498835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>29.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>126.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>47.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>120.000000</td>\n",
       "      <td>211.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>133.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>55.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>130.000000</td>\n",
       "      <td>240.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>153.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>140.000000</td>\n",
       "      <td>274.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>166.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.600000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>77.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>200.000000</td>\n",
       "      <td>564.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>202.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>6.200000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              age         sex          cp    trestbps        chol         fbs  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean    54.366337    0.683168    0.966997  131.623762  246.264026    0.148515   \n",
       "std      9.082101    0.466011    1.032052   17.538143   51.830751    0.356198   \n",
       "min     29.000000    0.000000    0.000000   94.000000  126.000000    0.000000   \n",
       "25%     47.500000    0.000000    0.000000  120.000000  211.000000    0.000000   \n",
       "50%     55.000000    1.000000    1.000000  130.000000  240.000000    0.000000   \n",
       "75%     61.000000    1.000000    2.000000  140.000000  274.500000    0.000000   \n",
       "max     77.000000    1.000000    3.000000  200.000000  564.000000    1.000000   \n",
       "\n",
       "          restecg     thalach       exang     oldpeak       slope          ca  \\\n",
       "count  303.000000  303.000000  303.000000  303.000000  303.000000  303.000000   \n",
       "mean     0.528053  149.646865    0.326733    1.039604    1.399340    0.729373   \n",
       "std      0.525860   22.905161    0.469794    1.161075    0.616226    1.022606   \n",
       "min      0.000000   71.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000  133.500000    0.000000    0.000000    1.000000    0.000000   \n",
       "50%      1.000000  153.000000    0.000000    0.800000    1.000000    0.000000   \n",
       "75%      1.000000  166.000000    1.000000    1.600000    2.000000    1.000000   \n",
       "max      2.000000  202.000000    1.000000    6.200000    2.000000    4.000000   \n",
       "\n",
       "             thal      target  \n",
       "count  303.000000  303.000000  \n",
       "mean     2.313531    0.544554  \n",
       "std      0.612277    0.498835  \n",
       "min      0.000000    0.000000  \n",
       "25%      2.000000    0.000000  \n",
       "50%      2.000000    1.000000  \n",
       "75%      3.000000    1.000000  \n",
       "max      3.000000    1.000000  "
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "int64      13\n",
       "float64     1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtypes.value_counts() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_categorical = ['sex', 'cp', 'restecg', 'exang', 'slope', 'ca', 'thal']\n",
    "\n",
    "feat_numeric = ['age', 'trestbps', 'chol', 'fbs', 'thalach', 'oldpeak']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Splitting data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train/ test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(\n",
    "    data.loc[:, data.columns != 'target'],\n",
    "    data['target'],\n",
    "    train_size = 0.8, \n",
    "    random_state = 42, \n",
    "    stratify = data.target\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross-validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_splits = RepeatedStratifiedKFold(n_splits = 5, n_repeats = 3, random_state = 42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline built-up - V1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example I'm combining both numeric and categorical features. On top of that I'm training a random forest which I optimize through using grid search."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_numeric = Pipeline(steps=[\n",
    "    ('impute_num', SimpleImputer(\n",
    "        missing_values = np.nan, \n",
    "        strategy = 'median', \n",
    "        copy = False, \n",
    "        add_indicator = True)\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_categorical = Pipeline(steps=[\n",
    "    ('impute_cat', SimpleImputer(\n",
    "        missing_values = np.nan, \n",
    "        strategy = 'constant', \n",
    "        fill_value = 99999,\n",
    "        copy = False)\n",
    "    ),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_union = ColumnTransformer([\n",
    "    ('feat_numeric', pipe_numeric, feat_numeric),\n",
    "    ('feat_categorical', pipe_categorical, feat_categorical),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = Pipeline(steps=[\n",
    "    ('transformers', transformer_union),\n",
    "    ('model', RandomForestClassifier(class_weight = 'balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining parameters grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 256,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = { \n",
    "    'model__n_estimators': [200, 500, 700],\n",
    "    'model__max_features': [2, 4, 6],\n",
    "    'model__max_depth' : [2, 4, 6]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    model_pipeline, \n",
    "    grid_param, \n",
    "    scoring = ['roc_auc'],\n",
    "    cv = cv_splits, \n",
    "    refit = 'roc_auc'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__n_estimators': [200, 500, 700],\n",
       " 'model__max_features': [2, 4, 6, 8],\n",
       " 'model__max_depth': [2, 4, 6, 8, 10]}"
      ]
     },
     "execution_count": 257,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the meta-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<sklearn.model_selection._split.RepeatedStratifiedKFold object at 0x12b219d50>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('transformers',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('feat_numeric',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('impute_stage',\n",
       "                                                                                          Simpl...\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators='warn',\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'model__max_depth': [2, 4, 6, 8, 10],\n",
       "                         'model__max_features': [2, 4, 6, 8],\n",
       "                         'model__n_estimators': [200, 500, 700]},\n",
       "             pre_dispatch='2*n_jobs', refit='roc_auc', return_train_score=False,\n",
       "             scoring=['roc_auc'], verbose=0)"
      ]
     },
     "execution_count": 258,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__max_depth': 8, 'model__max_features': 2, 'model__n_estimators': 200}\n",
      "0.92 AUC\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(round(grid_search.best_score_, 2), 'AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.913\n",
      "0.029\n"
     ]
    }
   ],
   "source": [
    "print(round(grid_search.cv_results_['mean_test_roc_auc'].mean(), 3))\n",
    "print(round(grid_search.cv_results_['std_test_roc_auc'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.88785183, 0.11214817],\n",
       "       [0.63254838, 0.36745162],\n",
       "       [0.9624782 , 0.0375218 ],\n",
       "       [0.30707293, 0.69292707],\n",
       "       [0.49277115, 0.50722885]])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since everything is wrapped into one big pipeline, it's sufficient to just call 'predict' on the\n",
    "# pipeline object\n",
    "\n",
    "grid_search.predict_proba(x_test)[:5, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 57., 150., 276., ...,   1.,   0.,   0.],\n",
       "       [ 67., 125., 254., ...,   0.,   0.,   1.],\n",
       "       [ 46., 140., 311., ...,   0.,   0.,   1.],\n",
       "       ...,\n",
       "       [ 54., 110., 239., ...,   0.,   0.,   1.],\n",
       "       [ 58., 150., 270., ...,   0.,   0.,   1.],\n",
       "       [ 49., 130., 266., ...,   0.,   1.,   0.]])"
      ]
     },
     "execution_count": 293,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# All the transformations made to the data are available under the main aggregation pipeline called 'transformer union'\n",
    "\n",
    "transformer_union.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.927\n"
     ]
    }
   ],
   "source": [
    "# Comparing the performance of the model on the test set\n",
    "\n",
    "print(round(roc_auc_score(y_test, grid_search.predict_proba(x_test)[:, 1]), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline built-up - V2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example I'm building V1 up by adding a set of additional binary variables calculated based on kmeans from the numeric input, and a pre-modelling feature selection piece with Lasso in the pipeline."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_num = Pipeline(steps=[\n",
    "    ('impute_num', SimpleImputer(\n",
    "        missing_values = np.nan, \n",
    "        strategy = 'median', \n",
    "        copy = False, \n",
    "        add_indicator = True))\n",
    "])\n",
    "\n",
    "discretize_num = Pipeline(steps=[\n",
    "    ('impute_num', SimpleImputer(\n",
    "        missing_values = np.nan, \n",
    "        strategy = 'mean', \n",
    "        copy = False)),\n",
    "    ('discretize_num', KBinsDiscretizer(\n",
    "        strategy = 'kmeans')),\n",
    "    ('select_num', SelectFromModel(Lasso(alpha = 0.5)))\n",
    "])\n",
    "\n",
    "pipe_numeric = Pipeline(steps=[\n",
    "    ('union_num', FeatureUnion([\n",
    "        ('impute_num', impute_num),\n",
    "        ('discretize_num', discretize_num)\n",
    "    ])\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>trestbps</th>\n",
       "      <th>chol</th>\n",
       "      <th>fbs</th>\n",
       "      <th>thalach</th>\n",
       "      <th>oldpeak</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>69</td>\n",
       "      <td>140</td>\n",
       "      <td>239</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>1.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>247</th>\n",
       "      <td>66</td>\n",
       "      <td>160</td>\n",
       "      <td>246</td>\n",
       "      <td>0</td>\n",
       "      <td>120</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>289</th>\n",
       "      <td>55</td>\n",
       "      <td>128</td>\n",
       "      <td>205</td>\n",
       "      <td>0</td>\n",
       "      <td>130</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>288</th>\n",
       "      <td>57</td>\n",
       "      <td>110</td>\n",
       "      <td>335</td>\n",
       "      <td>0</td>\n",
       "      <td>143</td>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>60</th>\n",
       "      <td>71</td>\n",
       "      <td>110</td>\n",
       "      <td>265</td>\n",
       "      <td>1</td>\n",
       "      <td>130</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>65</td>\n",
       "      <td>160</td>\n",
       "      <td>360</td>\n",
       "      <td>0</td>\n",
       "      <td>151</td>\n",
       "      <td>0.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>50</td>\n",
       "      <td>129</td>\n",
       "      <td>196</td>\n",
       "      <td>0</td>\n",
       "      <td>163</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>140</th>\n",
       "      <td>51</td>\n",
       "      <td>120</td>\n",
       "      <td>295</td>\n",
       "      <td>0</td>\n",
       "      <td>157</td>\n",
       "      <td>0.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>114</th>\n",
       "      <td>55</td>\n",
       "      <td>130</td>\n",
       "      <td>262</td>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>110</th>\n",
       "      <td>64</td>\n",
       "      <td>180</td>\n",
       "      <td>325</td>\n",
       "      <td>0</td>\n",
       "      <td>154</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>242 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     age  trestbps  chol  fbs  thalach  oldpeak\n",
       "19    69       140   239    0      151      1.8\n",
       "247   66       160   246    0      120      0.0\n",
       "289   55       128   205    0      130      2.0\n",
       "288   57       110   335    0      143      3.0\n",
       "60    71       110   265    1      130      0.0\n",
       "..   ...       ...   ...  ...      ...      ...\n",
       "39    65       160   360    0      151      0.8\n",
       "104   50       129   196    0      163      0.0\n",
       "140   51       120   295    0      157      0.6\n",
       "114   55       130   262    0      155      0.0\n",
       "110   64       180   325    0      154      0.0\n",
       "\n",
       "[242 rows x 6 columns]"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[x_train.columns.intersection(feat_numeric)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(242, 13)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe_numeric.fit_transform(x_train, y_train).shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_categorical = Pipeline(steps=[\n",
    "    ('impute_cat', SimpleImputer(\n",
    "        missing_values = np.nan, \n",
    "        strategy = 'constant', \n",
    "        fill_value = 99999,\n",
    "        copy = False)\n",
    "    ),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_union = ColumnTransformer([\n",
    "    ('feat_numeric', pipe_numeric, feat_numeric),\n",
    "    ('feat_categorical', pipe_categorical, feat_categorical),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Meta-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = Pipeline(steps=[\n",
    "    ('transformers', transformer_union),\n",
    "    ('model', RandomForestClassifier(class_weight = 'balanced'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Defining parameters grid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "grid_param = { \n",
    "    'model__n_estimators': [200, 500, 700],\n",
    "    'model__max_features': [2, 4, 6],\n",
    "    'model__max_depth' : [2, 4, 6]\n",
    "}\n",
    "\n",
    "grid_search = GridSearchCV(\n",
    "    model_pipeline, \n",
    "    grid_param, \n",
    "    scoring = ['roc_auc'],\n",
    "    cv = cv_splits, \n",
    "    refit = 'roc_auc'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model__n_estimators': [200, 500, 700],\n",
       " 'model__max_features': [2, 4, 6],\n",
       " 'model__max_depth': [2, 4, 6]}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_param"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting the meta-pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<sklearn.model_selection._split.RepeatedStratifiedKFold object at 0x11d9e7790>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('transformers',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('feat_numeric',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('union_num',\n",
       "                                                                                          FeatureU...\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators='warn',\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'model__max_depth': [2, 4, 6],\n",
       "                         'model__max_features': [2, 4, 6],\n",
       "                         'model__n_estimators': [200, 500, 700]},\n",
       "             pre_dispatch='2*n_jobs', refit='roc_auc', return_train_score=False,\n",
       "             scoring=['roc_auc'], verbose=0)"
      ]
     },
     "execution_count": 99,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "grid_search.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'model__max_depth': 4, 'model__max_features': 2, 'model__n_estimators': 200}\n",
      "0.92 AUC\n"
     ]
    }
   ],
   "source": [
    "print(grid_search.best_params_)\n",
    "print(round(grid_search.best_score_, 2), 'AUC')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.915\n",
      "0.029\n"
     ]
    }
   ],
   "source": [
    "print(round(grid_search.cv_results_['mean_test_roc_auc'].mean(), 3))\n",
    "print(round(grid_search.cv_results_['std_test_roc_auc'].mean(), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.80830587, 0.19169413],\n",
       "       [0.69689503, 0.30310497],\n",
       "       [0.88008589, 0.11991411],\n",
       "       [0.35649438, 0.64350562],\n",
       "       [0.51033467, 0.48966533]])"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Since everything is wrapped into one big pipeline, it's sufficient to just call 'predict' on the\n",
    "# pipeline object\n",
    "\n",
    "grid_search.predict_proba(x_test)[:5, ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.919\n"
     ]
    }
   ],
   "source": [
    "# Comparing the performance of the model on the test set\n",
    "\n",
    "print(round(roc_auc_score(y_test, grid_search.predict_proba(x_test)[:, 1]), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pipeline built-up - V3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this example I'm building V2 up by combining two different scoring algorithms in an ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Numerical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "impute_num = Pipeline(steps=[\n",
    "    ('impute_num', SimpleImputer(\n",
    "        missing_values = np.nan, \n",
    "        strategy = 'median', \n",
    "        copy = False, \n",
    "        add_indicator = True))\n",
    "])\n",
    "\n",
    "discretize_num = Pipeline(steps=[\n",
    "    ('impute_num', SimpleImputer(\n",
    "        missing_values = np.nan, \n",
    "        strategy = 'mean', \n",
    "        copy = False)),\n",
    "    ('discretize_num', KBinsDiscretizer(\n",
    "        strategy = 'kmeans')),\n",
    "    ('select_num', SelectFromModel(Lasso(alpha = 0.5)))\n",
    "])\n",
    "\n",
    "pipe_numeric = Pipeline(steps=[\n",
    "    ('union_num', FeatureUnion([\n",
    "        ('impute_num', impute_num),\n",
    "        ('discretize_num', discretize_num)\n",
    "    ])\n",
    "    )\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Categorical features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_categorical = Pipeline(steps=[\n",
    "    ('impute_cat', SimpleImputer(\n",
    "        missing_values = np.nan, \n",
    "        strategy = 'constant', \n",
    "        fill_value = 99999,\n",
    "        copy = False)\n",
    "    ),\n",
    "    ('one_hot', OneHotEncoder(handle_unknown='ignore'))\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining transformers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformer_union = ColumnTransformer([\n",
    "    ('feat_numeric', pipe_numeric, feat_numeric),\n",
    "    ('feat_categorical', pipe_categorical, feat_categorical),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Meta-pipeline and grid for each model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It's best to train and optimize parameters of each model individuall before we fit the ensemble."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Random Forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<sklearn.model_selection._split.RepeatedStratifiedKFold object at 0x12793d350>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('transformers',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('feat_numeric',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('union_num',\n",
       "                                                                                          FeatureU...\n",
       "                                                               min_weight_fraction_leaf=0.0,\n",
       "                                                               n_estimators='warn',\n",
       "                                                               n_jobs=None,\n",
       "                                                               oob_score=False,\n",
       "                                                               random_state=None,\n",
       "                                                               verbose=0,\n",
       "                                                               warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'model__max_depth': [2, 4, 6],\n",
       "                         'model__max_features': [2, 4, 6],\n",
       "                         'model__n_estimators': [200, 500, 700]},\n",
       "             pre_dispatch='2*n_jobs', refit='roc_auc', return_train_score=False,\n",
       "             scoring=['roc_auc'], verbose=0)"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline_rf = Pipeline(steps=[\n",
    "    ('transformers', transformer_union),\n",
    "    ('model', RandomForestClassifier(class_weight = 'balanced'))\n",
    "])\n",
    "\n",
    "grid_param_rf = { \n",
    "    'model__n_estimators': [200, 500, 700],\n",
    "    'model__max_features': [2, 4, 6],\n",
    "    'model__max_depth' : [2, 4, 6]\n",
    "}\n",
    "\n",
    "grid_search_rf = GridSearchCV(\n",
    "    model_pipeline_rf,\n",
    "    grid_param_rf,  \n",
    "    scoring = ['roc_auc'],\n",
    "    cv = cv_splits, \n",
    "    refit = 'roc_auc'\n",
    ")\n",
    "\n",
    "grid_search_rf.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Elastic-Net"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=<sklearn.model_selection._split.RepeatedStratifiedKFold object at 0x12793d350>,\n",
       "             error_score='raise-deprecating',\n",
       "             estimator=Pipeline(memory=None,\n",
       "                                steps=[('transformers',\n",
       "                                        ColumnTransformer(n_jobs=None,\n",
       "                                                          remainder='drop',\n",
       "                                                          sparse_threshold=0.3,\n",
       "                                                          transformer_weights=None,\n",
       "                                                          transformers=[('feat_numeric',\n",
       "                                                                         Pipeline(memory=None,\n",
       "                                                                                  steps=[('union_num',\n",
       "                                                                                          FeatureU...\n",
       "                                                           multi_class='warn',\n",
       "                                                           n_jobs=None,\n",
       "                                                           penalty='elasticnet',\n",
       "                                                           random_state=None,\n",
       "                                                           solver='saga',\n",
       "                                                           tol=0.0001,\n",
       "                                                           verbose=0,\n",
       "                                                           warm_start=False))],\n",
       "                                verbose=False),\n",
       "             iid='warn', n_jobs=None,\n",
       "             param_grid={'model__C': [0.03125, 0.0625, 0.125, 0.25, 0.5, 1],\n",
       "                         'model__l1_ratio': [0, 0.2, 0.4, 0.6, 0.8, 1]},\n",
       "             pre_dispatch='2*n_jobs', refit='roc_auc', return_train_score=False,\n",
       "             scoring=['roc_auc'], verbose=0)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model_pipeline_en = Pipeline(steps=[\n",
    "    ('transformers', transformer_union),\n",
    "    ('model', LogisticRegression(penalty = 'elasticnet', solver = 'saga', class_weight = 'balanced'))\n",
    "])\n",
    "\n",
    "grid_param_en = { \n",
    "    'model__l1_ratio': [0, 0.2, 0.4, 0.6, 0.8, 1],\n",
    "    'model__C': [2**i for i in range(-5,1)] # the level of regularization is specified differently\n",
    "}\n",
    "\n",
    "grid_search_en = GridSearchCV(\n",
    "    model_pipeline_en,\n",
    "    grid_param_en,  \n",
    "    scoring = ['roc_auc'],\n",
    "    cv = cv_splits, \n",
    "    refit = 'roc_auc'\n",
    ")\n",
    "\n",
    "grid_search_en.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training the Ensemble learner"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we build the ensemble object from both, already trained models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble = VotingClassifier(estimators=[\n",
    "    ('rf', grid_search_rf), \n",
    "    ('en', grid_search_en)], voting = 'soft', )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble.get_params().keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VotingClassifier(estimators=[('rf',\n",
       "                              GridSearchCV(cv=<sklearn.model_selection._split.RepeatedStratifiedKFold object at 0x12793d350>,\n",
       "                                           error_score='raise-deprecating',\n",
       "                                           estimator=Pipeline(memory=None,\n",
       "                                                              steps=[('transformers',\n",
       "                                                                      ColumnTransformer(n_jobs=None,\n",
       "                                                                                        remainder='drop',\n",
       "                                                                                        sparse_threshold=0.3,\n",
       "                                                                                        transformer_weights=None,\n",
       "                                                                                        transformers=[('feat_numeric',\n",
       "                                                                                                       Pipeline(memor...\n",
       "                                                                                         solver='saga',\n",
       "                                                                                         tol=0.0001,\n",
       "                                                                                         verbose=0,\n",
       "                                                                                         warm_start=False))],\n",
       "                                                              verbose=False),\n",
       "                                           iid='warn', n_jobs=None,\n",
       "                                           param_grid={'model__C': [0.03125,\n",
       "                                                                    0.0625,\n",
       "                                                                    0.125, 0.25,\n",
       "                                                                    0.5, 1],\n",
       "                                                       'model__l1_ratio': [0,\n",
       "                                                                           0.2,\n",
       "                                                                           0.4,\n",
       "                                                                           0.6,\n",
       "                                                                           0.8,\n",
       "                                                                           1]},\n",
       "                                           pre_dispatch='2*n_jobs',\n",
       "                                           refit='roc_auc',\n",
       "                                           return_train_score=False,\n",
       "                                           scoring=['roc_auc'], verbose=0))],\n",
       "                 flatten_transform=True, n_jobs=None, voting='soft',\n",
       "                 weights=None)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Executing this commented piece of code takes extremely long to execute. I suspect the Grid to re-estimate \n",
    "# the underlaying models again. For now I'm taking an easier path\n",
    "# grid_param_ensemble = { \n",
    "#     'weights': [[1, 1]]\n",
    "# }\n",
    "\n",
    "# grid_search_ensemble = GridSearchCV(\n",
    "#     ensemble, \n",
    "#     grid_param_ensemble, \n",
    "#     scoring = ['roc_auc'],\n",
    "#     cv = cv_splits, \n",
    "#     refit = 'roc_auc'\n",
    "# )\n",
    "\n",
    "# grid_search_ensemble.fit(x_train, y_train)\n",
    "\n",
    "ensemble.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Best model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ensemble_vc = cross_val_score(ensemble, x_train, y_train, cv = cv_splits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train:  0.924\n",
      "Test:  0.878\n"
     ]
    }
   ],
   "source": [
    "print('Train: ', round(roc_auc_score(y_train, ensemble.predict_proba(x_train)[:, 1]), 3))\n",
    "print('Test: ', round(roc_auc_score(y_test, ensemble.predict_proba(x_test)[:, 1]), 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Making predictions on test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.84048787, 0.15951213],\n",
       "       [0.55041368, 0.44958632],\n",
       "       [0.85116448, 0.14883552],\n",
       "       [0.39857579, 0.60142421],\n",
       "       [0.44894229, 0.55105771]])"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ensemble.predict_proba(x_test)[:5, ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Original pipeline reference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_pipeline = Pipeline(steps=[\n",
    "  (\"features\", FeatureUnion([\n",
    "    (\n",
    "      \"numerical_features\",\n",
    "      ColumnTransformer([\n",
    "        (\n",
    "          \"numerical\",\n",
    "          Pipeline(steps=[(\n",
    "            \"impute_stage\",\n",
    "            SimpleImputer(missing_values=np.nan, strategy=\"median\",)\n",
    "          )]),\n",
    "          [\"feature_1\"]\n",
    "        )\n",
    "      ])\n",
    "    ), (\n",
    "      \"categorical_features\",\n",
    "      ColumnTransformer([\n",
    "        (\n",
    "          \"country_encoding\",\n",
    "          Pipeline(steps=[\n",
    "            (\"ohe\", OneHotEncoder(handle_unknown=\"ignore\")),\n",
    "            (\"reduction\", NMF(n_components=8)),\n",
    "          ]),\n",
    "          [\"country\"],\n",
    "        ),\n",
    "      ])\n",
    "    ), (\n",
    "      \"text_features\",\n",
    "      ColumnTransformer([\n",
    "        (\n",
    "          \"title_vec\",\n",
    "          Pipeline(steps=[\n",
    "            (\"tfidf\", TfidfVectorizer()),\n",
    "            (\"reduction\", NMF(n_components=50)),\n",
    "          ]),\n",
    "          \"title\"\n",
    "        )\n",
    "      ])\n",
    "    )\n",
    "  ])),\n",
    "  (\"classifiers\", RandomForestClassifier())\n",
    "])\n",
    "\n",
    "model_pipeline.fit(train_data, train_labels.values)\n",
    "predictions = model_pipeline.predict(predict_data)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
